{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains examples of prompt engineering and LLM API (OpenAI) usage. Inspired by [DAIR.AI](https://github.com/dair-ai) guides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import IPython\n",
    "from langchain.llms import OpenAI\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API configuration\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# for LangChain\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"SERPAPI_API_KEY\"] = os.getenv(\"SERPAPI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model parameters\n",
    "def set_open_params(\n",
    "    model=\"text-davinci-003\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=256,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    "):\n",
    "\n",
    "    openai_params = {}\n",
    "    openai_params['model'] = model\n",
    "    openai_params['temperature'] = temperature\n",
    "    openai_params['max_tokens'] = max_tokens\n",
    "    openai_params['top_p'] = top_p\n",
    "    openai_params['frequency_penalty'] = frequency_penalty\n",
    "    openai_params['presence_penalty'] = presence_penalty\n",
    "    return openai_params\n",
    "\n",
    "def get_completion(params, prompt):\n",
    "\n",
    "    response = openai.Completion.create(\n",
    "        engine = params['model'],\n",
    "        prompt = prompt,\n",
    "        temperature = params['temperature'],\n",
    "        max_tokens = params['max_tokens'],\n",
    "        top_p = params['top_p'],\n",
    "        frequency_penalty = params['frequency_penalty'],\n",
    "        presence_penalty = params['presence_penalty'],\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic prompt: text completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = set_open_params()\n",
    "\n",
    "prompt = \"The human brain is\"\n",
    "\n",
    "response = get_completion(params, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       " the most complex organ in the human body. It is responsible for controlling many of the body’s functions, processing sensory information, and creating thoughts and memories. The brain contains billions of neurons, which are connected to each other by synapses. These neurons communicate with each other through electrical and chemical signals. The brain is divided into four main sections, which are the cerebrum, the cerebellum, the brainstem, and the hypothalamus. Each of these sections has different functions and is responsible for different aspects of the brain’s activities."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IPython.display.Markdown(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       " the most complex organ in the human body. It is responsible for controlling and coordinating body functions, as well as processing information from the senses. It is made up of billions of neurons that communicate with each other through electrical and chemical signals. The brain is divided into four main parts: the cerebrum, the cerebellum, the brainstem, and the hypothalamus. Each part has its own unique functions and roles in the body. The cerebrum is the largest part of the brain and is responsible for higher-level thinking, such as problem solving, decision making, and language. The cerebellum is responsible for coordinating movement and balance. The brainstem is responsible for controlling basic body functions, such as breathing, heart rate, and blood pressure. The hypothalamus is responsible for regulating hormones and controlling hunger, thirst, and body temperature."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# changing temperature\n",
    "params = set_open_params(temperature=0)\n",
    "prompt = \"The human brain is\"\n",
    "response = get_completion(params, prompt)\n",
    "IPython.display.Markdown(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       " A gravitational wave is a ripple in the fabric of spacetime caused by the acceleration of a large mass. These waves are predicted by Albert Einstein's general theory of relativity, and are detectable by measuring tiny changes in the distance between two distant objects."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = set_open_params()\n",
    "prompt = '''Question: What is a gravitational wave?\n",
    "Answer:'''\n",
    "response = get_completion(params, prompt)\n",
    "IPython.display.Markdown(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "A gravitational wave is a rippling in the fabric of space-time caused by the acceleration of a massive object. It is a type of wave that can travel through space and time, carrying with it information about its source and the nature of gravity that produced it."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = set_open_params()\n",
    "prompt = '''What is a gravitational wave?'''\n",
    "response = get_completion(params, prompt)\n",
    "IPython.display.Markdown(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context-based Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       " The name Esperanto comes from Dr. Esperanto's International Language, a pseudonym used by L. L. Zamenhof when publishing the language."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"Answer the question based on the context below. Keep the answer short and concise.\n",
    "Respond \"Not sure\" if unable to get the answer.\n",
    "\n",
    "Context: Esperanto is the world's most widely spoken constructed international auxiliary language.\n",
    "Created by the ophthalmologist L. L. Zamenhof in 1887, it was intended to be a universal second language\n",
    "for international communication, or \"the international language\". Zamenhof first described the language\n",
    "in Dr. Esperanto's International Language, which he published under the pseudonym Doktoro Esperanto.\n",
    "Early adopters of the language liked the name and soon used it to describe his language. \n",
    "\n",
    "Question: Where does the name Esperanto come from? \n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "response = get_completion(params, prompt)\n",
    "IPython.display.Markdown(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       " Neutral"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"Classify the text into neutral, negative or positive.\n",
    "\n",
    "Text: This movie was not so bad.\n",
    "\n",
    "Sentiment:\"\"\"\n",
    "\n",
    "response = get_completion(params, prompt)\n",
    "IPython.display.Markdown(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       " Positive"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"Classify the text into neutral, negative or positive.\n",
    "\n",
    "Text: This movie was so bad that it's ridiculously good.\n",
    "\n",
    "Sentiment:\"\"\"\n",
    "\n",
    "response = get_completion(params, prompt)\n",
    "IPython.display.Markdown(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       " Sarcastic"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now for something trickier: sarcasm detection\n",
    "prompt = \"\"\"Classify the text's tone into sarcastic or neutral.\n",
    "\n",
    "Text: My coffee machine broke again. That's just perfect.\n",
    "\n",
    "Tone: Sarcastic\n",
    "\n",
    "Text: I didn't watch the movie yesterday. Maybe next time.\n",
    "\n",
    "Tone: Neutral\n",
    "\n",
    "Text: They finally got their package delivered.\n",
    "\n",
    "Tone: Neutral\n",
    "\n",
    "Text: He's going to fire the whole department, how lovely.\n",
    "\n",
    "Tone: Sarcastic\n",
    "\n",
    "Text: Great, the cat is scratching the new sofa.\n",
    "\n",
    "Tone:\"\"\"\n",
    "\n",
    "response = get_completion(params, prompt)\n",
    "IPython.display.Markdown(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "def hanoi_tower(disk_number, source, auxiliary, destination):\n",
       "    if disk_number == 1:\n",
       "        print(\"Move disk 1 from\", source, \"to\", destination)\n",
       "        return\n",
       "    \n",
       "    hanoi_tower(disk_number-1, source, destination, auxiliary)\n",
       "    print(\"Move disk\", disk_number, \"from\", source, \"to\", destination)\n",
       "    hanoi_tower(disk_number-1, auxiliary, source, destination)\n",
       "\n",
       "hanoi_tower(3, \"A\", \"B\", \"C\")"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = 'Write a Python function that solves Hanoi Tower puzzle'\n",
    "\n",
    "response = get_completion(params, prompt)\n",
    "IPython.display.Markdown(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "SELECT \n",
       "    YEAR(purchases.PurchaseDate) AS Year, \n",
       "    MONTH(purchases.PurchaseDate) AS Month, \n",
       "    AVG(items.Price) AS AvgPurchaseSum \n",
       "FROM purchases \n",
       "JOIN items \n",
       "    ON purchases.ItemId = items.ItemId \n",
       "JOIN users \n",
       "    ON purchases.UserId = users.UserId \n",
       "WHERE users.Age BETWEEN 18 AND 24 \n",
       "GROUP BY Year, Month;"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = '''Table users, columns = [UserId, Age]\n",
    "Table items, columns = [ItemId, Price]\n",
    "Table purchases, columns = [PurchaseId, ItemId, UserId, PurchaseDate]\n",
    "Create a query to get average purchase sum per month by 18-24 year old users'''\n",
    "\n",
    "response = get_completion(params, prompt)\n",
    "IPython.display.Markdown(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Role playing: language learning practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       " 'Jahren' is the plural form of 'Jahr', so you need to say 'Sie ist vier Jahre alt.'"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"The following is a speaking practice in German with a teacher who also speaks English.\n",
    "The teacher is friendly, corrects mistakes and provides explanation in English.\n",
    "\n",
    "Teacher: Guten Morgen! Heute sprechen wir über Haustiere. Hast du ein Haustier? \n",
    "Student: Ja, ich habe ein Katze.\n",
    "Teacher: 'Katze' is a feminine noun, so it goes with a feminine article 'eine'. \n",
    "Student: Okay, ich habe eine Katze.\n",
    "Teacher: Super! Wie heißt sie?\n",
    "Student: Sie heißt Mia.\n",
    "Teacher: Und wie alt ist Mia?\n",
    "Student: Sie ist vier Jahren alt.\n",
    "Teacher:\"\"\"\n",
    "\n",
    "response = get_completion(params, prompt)\n",
    "IPython.display.Markdown(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain-of-thought prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       " Number of ways of getting three tails = C(4,3) = 4. Total number of ways = 2**4 = 16. \n",
       "P(three tails) = 4/16 = 1/4. The answer is 1/4."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"Question: Find the probability of getting two heads when five coins are tossed.\n",
    "Solution: Number of ways of getting two heads = C(5,2) = 10. Total number of ways = 2**5 = 32.\n",
    "P(two heads) = 10/32 = 5/16. The answer is 5/16.\n",
    "\n",
    "Question: Find the probability of getting three tails when four coins are tossed.\n",
    "Solution:\"\"\"\n",
    "\n",
    "response = get_completion(params, prompt)\n",
    "IPython.display.Markdown(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-shot Chain-of-thought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "First, calculate how many servings are needed: 4 people x 1 serving each = 4 servings.\n",
       "\n",
       "Second, calculate how many grams of spaghetti are needed: 4 servings x 100 grams per serving = 400 grams.\n",
       "\n",
       "Finally, calculate how many packages are needed: 400 grams of spaghetti divided by 250 grams per package = 1.6 packages.\n",
       "\n",
       "Therefore, you should buy 2 packages of spaghetti."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"Three friends of mine are coming over for dinner. I'd like to make pasta for everyone including myself.\n",
    "One package contains 250 grams of spaghetti. An average serving size is about 100 grams.\n",
    "How many packages should I buy?\n",
    "\n",
    "Let's think step by step.\"\"\"\n",
    "\n",
    "response = get_completion(params, prompt)\n",
    "IPython.display.Markdown(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# web search\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n",
    "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out when the Berlin Wall fell and then calculate the number of days since then.\n",
      "Action: Search\n",
      "Action Input: \"When did the Berlin Wall fall?\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mNovember 9, 1989\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to calculate the number of days since then\n",
      "Action: Calculator\n",
      "Action Input: Today's date minus November 9, 1989\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 12198\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: The Berlin Wall fell on November 9, 1989 and it has been 12198 days since then.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The Berlin Wall fell on November 9, 1989 and it has been 12198 days since then.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"When did the Berlin Wall fall? How many days passed since it came down as of today?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt templates\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Ich bin vor kurzem nach Hamburg gezogen.', additional_kwargs={})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "USER_INPUT = \"I recently moved to Hamburg.\"\n",
    "FINAL_PROMPT = \"\"\"Translate the text into German. \n",
    "\n",
    "Text: {user_input}. \n",
    "Translation:\"\"\"\n",
    "\n",
    "chat([HumanMessage(content=FINAL_PROMPT.format(user_input=USER_INPUT))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = '''You are an assistant that can classify the topic of input texts.\n",
    "The labels you can use are {topic_labels}. Name the topic of the following sentence:'''\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "human_template = \"{user_input}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The topic of the following sentence is news.', additional_kwargs={})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "\n",
    "chat(chat_prompt.format_prompt(topic_labels=\"news, sports, science\",\n",
    "                               user_input='''On Wednesday, the king was received with military honors on Pariser Platz\n",
    "                               in front of the Brandenburg Gate.''')\n",
    "     .to_messages())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The topic of the following sentence is science.', additional_kwargs={})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "\n",
    "chat(chat_prompt.format_prompt(topic_labels=\"news, sports, science\",\n",
    "                               user_input='''Functional neurologic disorder (FND), also known as conversion disorder\n",
    "                               and functional neurologic symptom disorder, refers to a group of common neurological\n",
    "                               movement disorders caused by an abnormality in how the brain functions.''')\n",
    "     .to_messages())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.10",
   "language": "python",
   "name": "python3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
